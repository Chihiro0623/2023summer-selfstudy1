# 연구노트 3주차 (7/17 - 7/21)
## 활동 내용
Classification 논문 Review 및 Presentation
Classification 모델 구현

## 논문 Review
| Week   | Paper                                               | Conf | Year   | Review   |
| :----: | ------------------------------------------------------- | :----: | :------------: | :------: |
| 3    | [mixup: Beyond Empirical Risk Minimization](https://arxiv.org/pdf/1710.09412.pdf)<br>[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)<br>[RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/pdf/1909.13719.pdf) | ICLR<br>ICML<br>CVPR  | 2018<br>2015<br>2020 | [Review](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week1/Reviews/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks.pdf)<br>[Review](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week1/Reviews/Very%20Deep%20Convolutional%20Networks%20for%20Large-Scale%20Image%20Recognition.pdf)<br>[Review](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week1/Reviews/Deep%20Residual%20Learning%20for%20Image%20Recognition.pdf) |



### mixup: Beyond Empirical Risk Minimization
mixup이라는 augmentation을 제시한 논문이다. [Presentation](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week3/Reviews/mixup_%20BEYOND%20EMPIRICAL%20RISK%20MINIMIZATION.pptx)

### Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift


### RandAugment: Practical automated data augmentation with a reduced search space





## 구현
[Project 2](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week3/Project/week2.pdf)  
[보고서](https://github.com/Chihiro0623/2023summer-selfstudy1/blob/main/week3/Project/Assignment2.pdf)  
